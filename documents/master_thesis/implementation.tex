\chapter{Implementation}
During this thesis I developed an application which is able to apply all the previously mentioned calculation methods for the load-flow calculation. Most of the application is written in \emph{C\#}, only \emph{HELM} is implemented as a \emph{C++}-library. This became necessary because of the superior abilities of templates over generics. I will give a more detailed explanation of these implementation details of the calculation methods in \secref{implementation_calculation_methods}.
As input formats there are two options available: a custom format, stored in a \emph{MS SQL}-Database, and the format used by \emph{PSS SINCAL}. I will explain the implementation of the later one in \secref{link_sincal}. Ahead of the discussion of these implementation details, I want to give you a short overview of the software architecture in the next section.

\section{Software Architecture}

\begin{figure}
	\centering
	\include{tikz/software_architecture}
	\caption{Overall software architecture}
	\label{fig:software_architecture}
\end{figure}

\begin{figure}
	\centering
	\include{tikz/calculation_architecture}
	\caption{Software architecture of the subsystem Calculation}
	\label{fig:calculation_architecture}
\end{figure}

The application is splitted up into several subprojects which build upon each other, as it can be seen in \figref{software_architecture}. The most important part is the Calculation, where the calculation methods are implemented. In \figref{calculation_architecture} this subproject is shown in detail; it is made out of hierarchical blocks too. This design has two big advantages: First of all, every single subsystem can be tested seperately, without the necessity to touch the other systems. Secondly, this design is more flexible. For instance, the consideration of unsymmetric situations could be achieved through three instances of a single phase net, one for each symmetric component.

In \chapref{calculation_api} I show how the API of the Calculation subsystem can be used. For more complex examples I would like to refer to the code of the unit tests.

\section{Calculation Methods}
\label{sec:implementation_calculation_methods}

\subsection{Iterative Methods}
I implemented all the iterative methods, like the \emph{Current Iteration}, \emph{Newton-Raphson} and \emph{FDLF}, in \emph{C\#}. For the linear algebra I used there the library \emph{math.net numerics} \footnote{http://numerics.mathdotnet.com/}, which had all the necessary tools already implemented. Of course, this library is not optimized for this special application. Therefore, it would definitely be possible to speed up the iterative methods, although \emph{math.net numerics} for instance already utilizes multiple cores. As the iterative methods are not the main focus of this work, I focussed on \emph{HELM} and just selected the best fitting methods from the library, instead of reimplementing and optimizing them.

\subsection{Holomorphic Embedding Load Flow}
\label{sec:implementation_helm}
For the implementation of the calculation methods I want to explain first the decision to implement \emph{HELM} in a separate library, written in \emph{C++}. Unfortunately, in some cases the mantissa of a 64 Bit floating point is not sufficient to benefit from the theoretical ideal convergence behaviour of \emph{HELM}. The problem here lies within the very small convergence radius of \eqref{helm_series}. As already mentioned before, the theoretical solution to this is an analytic continuation. At this point then the actual problem is buried, in \emph{Wynn's Epsilon Algorithm} only every second column is converging, the other columns between diverge. Approximately with 50 coefficients the divergence is already at the barrier of the precision of a 64 Bit floating point. The calculation of more coefficients does not improve the results anymore, because the numerical error, caused by the machine epsilon, is bigger than the possible gain in accuracy.

\begin{figure}
	\centering
	\include{tikz/convergence_border_net}
	\caption{Test net for convergence border}
	\label{fig:convergence_border_net}
\end{figure}

To give a more demonstrative explanation, I want to show you the results of a comparison of the convergence behaviour of the different algorithms. For this purpose I used the net \figref{convergence_border_net}, which is stable for $P \le \SI{0.25}{W}$. In this net I increased the power as long as the algorithm did converge and noted down the value closest to the border of stability. The result of this procedure is \figref{convergence_border}, in which it can be seen that a more accurate floating point datatype enables \emph{HELM} to get closer to the border of stability. The use of \emph{HELM} with only 64 Bit for the initial voltages is already an improvement over the direct application of the \emph{Current Iteration} and \emph{Newton-Raphson} in terms of convergence behaviour. But in the end, only \emph{HELM} with an arbitrary precise datatype is able to get as close as desired to the border of stability, although this advantage is traded in for a lot worse performance.

\begin{figure}
	\centering
	\includegraphics[scale=0.7]{figures/convergence_border}
	\caption{Convergence border for \figref{convergence_border_net}}
	\label{fig:convergence_border}
\end{figure}

To be able to evaluate \emph{HELM} in detail, also for critical nets, which can not be calculated with the iterative methods, I decided to implement \emph{HELM} with the possibility of a configurable precise datatype. As the generics in \emph{C\#} did not gave me the ability to use a library of precise datatypes together with a package for linear algebra, I decided to switch for this part of the application to \emph{C++}. In this language I had templates available, which allowed the combination of \emph{MPIR} \footnote{http://mpir.org/}, a library for multi precision integers and rationals, with a library for sparse linear algebra, like \emph{Eigen} \footnote{http://eigen.tuxfamily.org/}.

\subsection{Linear Algebra}
All the implemented methods have one thing in common: linear algebra. In all these methods it is necessary to solve linear equation systems, although the equation systems differ in their properties. In \emph{HELM} and the \emph{Current Iteration} the system matrix is the admittance matrix, in \emph{Newton-Raphson} and \emph{FDLF} it is a Jacobian matrix. Both types of matrices are typically sparse, therefore the use of sparse linear algebra improves the performance of the algorithms significantly.

To solve these linear equation systems with a LU-factorization is for big power net quite slow. The solution to this problem is to use iterative solvers like \emph{BiCGSTAB} \cite{bicgstab}.

The last important detail of the implementation of the calculation methods is the preconditioning. With this step special properties of the system matrix can be leveraged to improve the condition of the equation system and therefore accelerate the iterative solvers. Fortunately, the admittance matrix, which is the system matrix in the \emph{Current Iteration} and \emph{HELM}, is approximately diagonal dominant. This makes the application of a diagonal preconditioner very practical, because such a preconditioning is very efficient to calculate and improves the condition of the equation system significantly in this special case.

\subsubsection{Optimizations}
The application of the special conditions in \emph{HELM} allows a few optimizations, which can not be made in general. At the beginning I used \emph{Eigen} for the linear algebra, but with bigger power nets I ran into performance problems with this general purpose library. Consequently, I reimplemented the necessary data structures and algorithms:
\begin{itemize}
	\item Dense vector
	\item Sparse matrix
	\item Multiplication of a sparse matrix with a dense vector
	\item Various operations on dense vectors
	\item \emph{BiCGSTAB}
	\item LU-factorization
	\item Forward and back substitution
\end{itemize}

The specialization on dense vectors is useful in the case of \emph{HELM} as the solutions for the equation system will be typically dense. Therefore, there is no need to apply more complex operations on sparse vectors.

However, the system matrix of the linear equation system is the admittance matrix, which is sparse for big problems. In fact, the amount of nonzero values in every row is nearly independent of the size of the total matrix. The reason for this lies within the physical structure of a power net, where every node only as a limited number of neighbours, no matter how big the total graph is. Therefore, the density of the admittance matrix decreases with a growing problem size. For small problems this specialization is in fact a performance drawback, but for these problems the performance does not matter anyway.

As there must not be a zero-row, a version of a sparse matrix with one array for each row is superior over CRS \cite{sparseMatricesJava} or CCS \cite{sparseMatricesJava}. Through this decision regarding the internal representation of the sparse matrix, it is especially during the calculation of the LU-decomposition possible to avoid a lot of memory reallocations, which become the most expensive operations if the sparse matrix is represented internally as CRS or CCS. The decision to store the matrices row- and not column-oriented is related to the matrix multiplication and the forward and back substitution, which benefit in terms of runtime from this format.

The multiplication of a sparse matrix with a dense vector can then leverage the special sparse matrix format and the dense vectors. The key point is to iterate only over the nonzero elements over each row in the matrix and select the according elements of the vector in $\mathcal O(1)$. Additionally, the operation can be parallelized effectively, as all elements in the result vector are independent from each other.

Operations on the dense vectors, like the dot product or adding two vector, can be parallelized too. In this case the dense storage of the values is again very convenient, regarding the performance of the operations.

The iterative solver \emph{BiCGSTAB} benefits from the already optimized matrix and vector operations. Additionally, it is possible to avoid a few memory allocations and move operations through implementing all these operations in-place.

The calculation of a LU-factorization and the forward and back subsitution can not benefit from multiple cores well, at least for small datatypes like a double, where the floating point operations are not that expensive. For bigger datatypes with more expensive operations there is also a small speedup possible.

Last but not least I had also to concentrate on numerical stability. For this purpose, I sorted all values in ascending order before I summed them up. This special modification has of course a negative impact on the performance, but improves the convergence behaviour of \emph{HELM}.

\section{Link to PSS SINCAL}
\label{sec:link_sincal}
The tool of choice in europe, especially at the Institute of Power Transmission Systems at the Technische Universität München, for load-flow calculations is \emph{PSS SINCAL}. Consequently, the tool developed during this thesis has a parser for this file format. This parser allows to read a power net from the file and write back the calculated node voltages.

The basic structure of a power net in \emph{PSS SINCAL} is as follows:
\begin{itemize}
	\item {\textlangle}name{\textrangle}.sin
	\item {\textlangle}name{\textrangle\_}files
	\begin{itemize}
		\item database.001.dia
		\item database.ini
		\item database.mdb
	\end{itemize}
\end{itemize}

The main information about the electrical characteristics of the power net are stored in the \emph{MS Access}-database. Fortunately, this database is documented very well online \footnote{http://sincal.s3.amazonaws.com/doc/Misc/SINCAL\_Datenbankinterface.pdf} and by the documents delivered together with the application.

The most important tables in this database are:
\begin{itemize}
	\item Terminal: contains information about the connection of the net elements with the nodes
	\item VoltageLevel: mostly used for the frequency of the power net
	\item Element: contains all net elements
	\item Node: contains all nodes with their ID, name, voltage level, ... etc.
	\item TwoWindingTransformer, ThreeWindingTransformer, Line, SynchronousMachine, Load, Infeeder: contain the corresponding net elements
	\item LFNodeResult: contains the node results of the load-flow calculation
\end{itemize}

Of course, \emph{PSS SINCAL} supports a lot more net elements and ways to describe than the tool developed during this thesis. Therefore, for more complex or exotic selections in the database the tool will fail to parse the power net. Especially unsymmetric power nets and short circuit calculations are not supported by my tool. Consequently, the tool neglects the values related to these calculations.

For more detailed information about the database I would like to refer to the official documentation, or the implementation of the parser in the subsystem \emph{SincalConnector}. This part of the software has also a few unit tests, which may be used as documentation too.